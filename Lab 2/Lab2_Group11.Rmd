---
title: "Lab2 Group11"
author: "Group 10"
date: "28/01/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE, eval=TRUE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Question 1: Optimizing a model parameter

```{r, echo=FALSE, warning=FALSE}
# R version
RNGversion('3.5.1')
```

The aim of the first question is to perform optimization by using a data set, \texttt{mortality rate.csv}, consisting of information about the mortality rates of fruit flies during an observed period. 

### 1. 

First, we import the file to R, and then add a variable called \texttt{LMR} to the data set. The new defined variable \texttt{LMR} is the natural logarithm of \texttt{Rate}. Thereafter, we split the data into a training set and a test sets, respectively. The splitting is done using the code which is already given (see Appendix). 



### 2.

### 3.

### 4.

### 5.

### 6.



```{r}

```

# Question 2: Maximum likelihood

### 1. 

In this task we will use the file \texttt{data.RData} consists of a sample coming from normal distribution with parameters $\mu$ and $\sigma$. First we load the data set into R. 

```{r, echo=FALSE,include=FALSE}
# 2.1
# Load the data
# Sample from normal distribution with parameters \mu and \sigma
load("data.Rdata")
x <- data

```


### 2. 

The sample comes from a normal distribution with parameters $\mu$ and $\sigma$, where we set $\theta = (\mu,\sigma)$. Under the assumption that the sample $\boldsymbol{x}=(x_1,...,x_{100})$ is iid, i.e. $\boldsymbol{X_i} \stackrel{iid}\sim N(\mu, \sigma^2)$, for $i=1,...,100$, then the joint density function of all $n=100$ observations can be written as

$$
L(\theta; \boldsymbol{x})=f(\boldsymbol{x}| \theta) = \prod_{i=1}^{100} f(x_i|\theta).
$$

Now we let the number of observations be denoted by $n$ in the following derivations. Using the density function of a normal distribution with parameter $\theta$ we obtain the likelihood function

$$
L(\theta; \boldsymbol{x})= \prod_{i=1}^{n} \frac{1}{\sigma\sqrt{2\pi}}\ \text{exp}\bigg\{{-\frac{1}{2}\bigg(\frac{x_i-\mu}{\sigma}\bigg)^2}\bigg\}.
$$

The log-likelihood function is given by

$$
l(\theta; \boldsymbol{x}) = \text{log} \ L (\theta; \boldsymbol{x})
= -\frac{n}{2}\log(2\pi\sigma^2) -\frac{1}{2\sigma^2}\sum_{i=1}^{n} (x_i - \mu)^2.
$$

The maximum likelihood estimators (MLEs) $\hat{\mu}_{ML}$ and $\hat{\sigma}^2_{ML}$ of $\mu$ and $\sigma^2$ are obtained by maximizing the likelihood function. This is done by differentiating the log-likelihood functions and put them to zero. In more detail, we calculate the score functions $S(\theta; \boldsymbol{x})$ w.r.t. $\mu$ and $\sigma$ seperately, and let them equal zero and solve for each parameter:

$$
S(\mu)= \frac{\partial}{\partial\mu}\ l(\theta;\boldsymbol{x}) = -\frac{n(\overline{x}-\mu)}{\sigma^2}=0,
$$
 where $\overline{x} = \frac{1}{n}\sum_{i=1}^n x_i$. From this we obtain $\hat{\mu}_{ML} = \overline{x}$. Further, 
 
 
$$
S(\sigma)= \frac{\partial}{\partial\sigma}\ l(\theta;\boldsymbol{x}) = -\frac{n}{\sigma} + \frac{1}{\sigma^3}\sum_{i=1}^n(x_i-\mu)^2=0,
$$



and $\hat{\sigma}^2_{ML} = \frac{1}{n}\sum_{i=1}^n (x_i- \mu)^2$.


Then we use the derived formulas in order to obtain the desired parameter estimates for the loaded data. So the data set with 100 observations gives the result $\hat{\mu}_{ML}=1.275528$ and $\hat{\sigma}_{ML}=2.005976$. 



```{r, echo=FALSE,include=FALSE}
# 2.2
# Derived formulas for the MLE 
mu_ml <- function(x){
  mean(x)
}

sigma_ml <- function(x){
  term <- (x - mean(x))^2
  sigma <- sum(term)/length(x)
  return(sqrt(sigma))
}

# Value of MLE
mu <- mu_ml(x)
sigma <- sigma_ml(x)

```



### 3.

The function \texttt{optim()} minimizes the function by default in R. Thus we will optimize the minus log-likelihood function in order to find the maximum of the function. We will perform two types of algorithms, Conjugate Gradient and BFGS, both with gradient specified and without, to optimize the minus log-likelihood function. It is a better idea to maximize the log-likelihood than maximize the likelihood. This is due to the large values that occurs in the likelihood, which are numerically unstable, so it is preferable to take the logarithm which gives us a better scale to work with. Also, differentiating the log-likelihood function is more computationally convenient, since the product is replaced by a sum (see Question 2.2). 


```{r, echo=FALSE,include=FALSE}
# 2.3
# Minus logâ€“likelihood function
minus_logL <- function(x, par){
  mu <- par[1]
  sigma <- par[2]
  (length(x)/2)*log(2*pi*sigma^2) + 1/(2*sigma^2) * sum((x - mu)^2)
} 

# Gradient (also minus)
gradient <- function(x, par){
  mu <- par[1]
  sigma <- par[2]
  -c((1/sigma)^2 * sum(x - mu),
     -(length(x)/sigma) + (1/sigma)^3 * sum((x - mu)^2))
}

# Optimize with initial parameters mu = 0, sigma = 1.
# Set seed
set.seed(123456)

#--------------------------------------------------------------------
# Conjugate Gradient method
# Start time
start.time <- Sys.time()

# With a finite-difference approximation
optim(par = c(0, 1), fn = minus_logL, gr = NULL, method = "CG", x = x)

# End time
end.time <- Sys.time()
time.taken <- end.time - start.time 

#--------------------------------------------------------------------
# Conjugate Gradient method
# Start time
start.time <- Sys.time()

# With a specified gradient
optim(par = c(0, 1), fn = minus_logL, gr = gradient, method = "CG", x = x)

# End time
end.time <- Sys.time()
time.taken <- end.time - start.time 

#--------------------------------------------------------------------
# BFGS - With a finite-difference approximation
# Start time
start.time <- Sys.time()

# With a finite-difference approximation
optim(par = c(0, 1), fn = minus_logL, gr = NULL, method = "BFGS", x = x)

# End time
end.time <- Sys.time()
time.taken <- end.time - start.time 

#--------------------------------------------------------------------
# BFGS - With a specified gradient
# Start time
start.time <- Sys.time()

# Optimize
optim(par = c(0, 1), fn = minus_logL, gr = gradient, method = "BFGS", x = x)

# End time
end.time <- Sys.time()
time.taken <- end.time - start.time 


```


### 4.

The results of the optimization are presented in Table \ref{tab:result}. 


\begin{table}[h!]
\centering
\begin{tabular}{ c| c | c | c | c | c |c }
Algorithm & Gradient specified & $\hat\mu$ & $\hat{\sigma}$ & Function & Gradient & Time \\
\hline
Conjugate Gradient & No & 1.275528 & 2.005977 & 297 & 45 & 0.01877809 sec \\
Conjugate Gradient & Yes & 1.275528 & 2.005976 & 53 & 17 & 0.004215956 sec \\
BFGS & No & 1.275528 & 2.005977 & 37 & 15 & 0.005324841 sec \\
BFGS & Yes & 1.275528 & 2.005977 & 39 & 15 & 0.009279966 sec \\
\hline
\end{tabular}
\caption{\textit{Result of the optimization using the algorithms Conjugate Gradient and BFGS, for the given data set. The algorithms, gradient, optimal values of parameters, number of function and gradient evaluations and time taken are presented.}}
\label{tab:result}
\end{table}


From the results in Table \ref{tab:result}, we can see that the algorithm converged in all cases, where all the obtained optimal values are the same and correspond to the estimated parameters in Question 2.2. One explanation of why all algorithms find the optimum is because the likelihood function is convex for the normal distribution. Therefore, it is guaranteed that these algorithms will find the optimal values of the parameters.

Without specifying the gradient, the Conjugate Gradient method required $297$ function and $45$ gradient evaluations for the algorithm to converge, while the BFGS only required $37$ function and $15$ gradient evaluations. Also, the time until convergence was measured by using \texttt{Sys.time()}, and we can notice that the BFGS is somewhat faster than Conjugagte Gradient. Even though the difference in time between the algorithms is small, it may have a bigger impact when having a larger data set. All this support the recommendation of choosing the algorithm BFGS in this situation. When we specified the gradient, the number of evaluations was remarkably reduced and time decreased for the Conjugate Gradient algorithm. In this case, it could be reasonable to specify the gradient and not use a finite-difference approximation. On the other hand, there are no big difference when specify the gradient for the BFGS algorithm. 

In summary, the gradient adds more information to the optimization and therefore we recommend to specify the gradient if possible. If the gradient is not specified when optimizing, then the BFGS is a better choice in this case. 



# Appendix

```{r ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE}

```