#====================================================================
# COMPUTATIONAL STATISTICS - LAB 3
#====================================================================

# R version
RNGversion('3.5.1')
library(tidyverse)
library(rmutil)

#--------------------------------------------------------------------
# QUESTION 2 - Different distributions 
#--------------------------------------------------------------------


#2.1
# The quantile function q. of a probability distribution 
# is the inverse of its cumulative distribution function F.

# Location parameter centered at 0, which is reasonable.
# Scale parameter controls the width or spread of the distribution

# Random numbers from DE(0,1) from Unif(0,1) generated by using the inverse cumulative function.
# Divide the two cases into different statements. 
my_DE <- function(n){
  x <- c()
  for (i in 1:n){
    u <- runif(1)
    if(u < 0.5){
      x[i] <- log(2*u)
    }else{
      x[i] <- -log(2*(1-u))
    }
  }
  return(x)
}

# Random numbers from DE(0,1) from Unif(0,1) generated b using the inverse cumulative function.
# Use the sign function 

my_DE_sgn<- function(n){
  x <- c()
  for (i in 1:n){
    u <- runif(1)
    x[i] <- -sign(u-0.5)*log(1-2*abs(u-0.5))
  }
  return(x)
}
# Generate 10000 random numbers from DE(0,1)
x <- my_DE(10000)

# Histogram of the random nr
hist(x, breaks = 40)

# Looks reasonable since the Laplace with these settings, when x>0, is a scaled version of
# the exponential distribution with rate 1. 

# histogram of random numbers from an exponential distribution 
hist(0.5*rexp(10000,1), breaks = 40)
# The DE(0,1) using inv. cdf method corresponds to the histogram when directly sample from the laplace. 
hist(rlaplace(10000), breaks = 40) 

# 2.2
# inspiration from the code provided in the course material

# This works
fgennorm <- function(c){
  x <- NA
  num.reject <- 0
  while (is.na(x)){
    y <- my_DE(1) # majorizing density 
    u <- runif(1) # Unif(0,1)
    if (u <= dnorm(y)/(c*0.5*exp(-abs(y)))){x <- y}
    else{ num.reject <- num.reject + 1}
  }
  c(x, num.reject)
}

# c=1.32, see motivation below
set.seed(12345)
n <- 2000
A <- matrix(c(rep(0,n) ,rep(0,n)), ncol=2)
for (i in 1:n){
  A[i,] <- fgennorm(1.32)
}
hist(A[,1], breaks = 40)
hist(rnorm(2000), breaks = 40)

# Average rejection rate 
mean(A[,2])
# What is the expected rejection rate ER ?
# The number of draws are Geometric(1/c)  distributed with mean c.

# A value of c closer to 1 implies fewer rejected samples. Pick a c close to 1, 
# while still satisfying cfY(x) >= fX(x)

# there is a constant that fullfills: 
# Find c. 
nr <- A[,1] 
c_values <- seq(1,5,0.01)
for (i in seq_along(c_values)){
  if(all((c_values[i]*0.5*exp(-abs(nr)) >= dnorm(nr)))){
    c_value <- c_values[i]
    break()
  }
}
c_value

all(c_value*0.5*exp(-abs(nr)) >= dnorm(nr))
table(c_value*0.5*exp(-abs(nr)) >= dnorm(nr))

# ER-R =approx 1. 
# Reasonable since the number of rejections plus the draw when accepted must equal the total number of draws. 

# Pick a c close to 1. 

# the two histograms looks similar when comparing them. If we increase the number of random variables we will 
# obtain a even better shape. However it depends on the majorizing constant c

